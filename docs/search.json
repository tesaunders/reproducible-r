[
  {
    "objectID": "slides.html#objective",
    "href": "slides.html#objective",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Objective",
    "text": "Objective\nUnlock the full potential of your scripts by making your code reproducible, shareable, and citable.\nWorkshop repository:\nhttps://github.com/tesaunders/reproducible-r"
  },
  {
    "objectID": "slides.html#why",
    "href": "slides.html#why",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Why?",
    "text": "Why?\nMost R users are not software developers.\nApplying some software development princicples enables you to:\n\nWrite readable, reproducible, maintainable code\nSave time and frustration when using and maintaining code\nCollaborate more efficiently\nMake your research reusable, transparent, and rigorous"
  },
  {
    "objectID": "slides.html#problem-folders-are-a-mess",
    "href": "slides.html#problem-folders-are-a-mess",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Problem: Folders are a mess",
    "text": "Problem: Folders are a mess\n\nCan’t find anything quickly\nFiles are all over the place\nCan’t easily share what I’m working on"
  },
  {
    "objectID": "slides.html#solution-organising-r-code-into-projects",
    "href": "slides.html#solution-organising-r-code-into-projects",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Solution: Organising R code into projects",
    "text": "Solution: Organising R code into projects\n\nOrganise all files into consistent folder structures\nBreak long scripts into separate files based on the tasks being performed\nAdd a README file to describe the project"
  },
  {
    "objectID": "slides.html#problem-r-code-is-difficult-to-understand",
    "href": "slides.html#problem-r-code-is-difficult-to-understand",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Problem: R code is difficult to understand",
    "text": "Problem: R code is difficult to understand\nMany beginner programmers:\n\nDo not document their code\nRely on assigning objects instead of piping\nAre not aware of how to write their own functions\nGet stuck with how and why to iterate"
  },
  {
    "objectID": "slides.html#solution-write-clean-styled-documented-code",
    "href": "slides.html#solution-write-clean-styled-documented-code",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Solution: Write clean, styled, documented code",
    "text": "Solution: Write clean, styled, documented code\n\nUse comments to explain why you did something a particular way\nUse sections and subsections to organise and navigate longer scripts\nUse a consistent style (linting with {styler} or Air)\nWrite functions and iterate to do complex things at scale"
  },
  {
    "objectID": "slides.html#problem-difficult-to-collaborate-on-codeanalyses",
    "href": "slides.html#problem-difficult-to-collaborate-on-codeanalyses",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Problem: Difficult to collaborate on code/analyses",
    "text": "Problem: Difficult to collaborate on code/analyses\n\nEmailing back and forth is inefficient\nWorking by yourself is lonely :("
  },
  {
    "objectID": "slides.html#solution-use-a-version-control-system",
    "href": "slides.html#solution-use-a-version-control-system",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Solution: Use a version control system",
    "text": "Solution: Use a version control system\n\nGit - software installed on your machine which tracks versions of files\nGitHub - cloud service which allows you to share/collaborate on projects\nAll changes are kept, revertible, nothing is lost\nFeatures like issues (to do lists), code review, automatic checks"
  },
  {
    "objectID": "slides.html#problem-code-doesnt-run-after-package-updates",
    "href": "slides.html#problem-code-doesnt-run-after-package-updates",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Problem: Code doesn’t run after package updates",
    "text": "Problem: Code doesn’t run after package updates\n\nSometimes updates to packages break code"
  },
  {
    "objectID": "slides.html#solution-manage-dependencies-with-renv",
    "href": "slides.html#solution-manage-dependencies-with-renv",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Solution: Manage dependencies with {renv}",
    "text": "Solution: Manage dependencies with {renv}\nrenv takes a snapshot of currently used packages within a project.\n\nCreates a ‘lockfile’ containing the packages and versions you’ve used.\nCollaborator/reuser can get the same environment with one command.\nThis makes it far more likley the code will continue to work."
  },
  {
    "objectID": "slides.html#problem-many-researchers-dont-get-credit-for-their-code",
    "href": "slides.html#problem-many-researchers-dont-get-credit-for-their-code",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Problem: Many researchers don’t get credit for their code",
    "text": "Problem: Many researchers don’t get credit for their code\nLots of code is:\n\nnot recognised/rewarded as an output of research.\nnot easily findble and reusable by others.\nnot attached to data/results to enable reproducibility."
  },
  {
    "objectID": "slides.html#solution-publish-your-code",
    "href": "slides.html#solution-publish-your-code",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Solution: Publish your code",
    "text": "Solution: Publish your code\nTwo good options:\n\nGitHub repositories can be connected to Zenodo to get a DOI, OR\nPublish the code or a link to the GitHub repo with FigShare or Zenodo\n\n\nCode is more easily associated with other publications.\nCode is citable, and citations can be tracked.\nDOIs are persistent records that will always resolve to the right place."
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "See the online workshop notes to revisit the lesson in your own time.\nR for Data Science is highly recommended as a general purpose introduction to R, and particularly the Tidyverse ecosystem of packages.\nTidy data expands on some of the principles we talked about around keeping files and analyses organised.\nSee the renv documentation for an overview of how to use renv with your projects."
  },
  {
    "objectID": "05_publishing.html",
    "href": "05_publishing.html",
    "title": "Publishing",
    "section": "",
    "text": "Using R or another programming language to analyse your data means all the steps you’ve taken to get from data to results are laid out in your script. Having your code in a public GitHub repo is a great way to share that code in a way that makes it easier for others to immediately reuse it. But by ‘publishing’ that code (by getting a DOI) you can gain even more visibility for your software, and ensure you get credit for it.\nWe’ll discuss two options for publishing your code. Both will get you a DOI so your code becomes citable."
  },
  {
    "objectID": "05_publishing.html#connect-your-github-repo-with-zenodo",
    "href": "05_publishing.html#connect-your-github-repo-with-zenodo",
    "title": "Publishing",
    "section": "1. Connect your GitHub repo with Zenodo",
    "text": "1. Connect your GitHub repo with Zenodo\nIf you already have a Zenodo account, you can connect your GitHub. If you don’t have an account already, log in to Zenodo with your GitHub account.\nThen go here and toggle the button next to the repo on. Zenodo will archive your repository (and will issue a new DOI each time you create a new GitHub release)."
  },
  {
    "objectID": "05_publishing.html#connect-your-github-repo-with-figshare",
    "href": "05_publishing.html#connect-your-github-repo-with-figshare",
    "title": "Publishing",
    "section": "2. Connect your GitHub repo with FigShare",
    "text": "2. Connect your GitHub repo with FigShare\nIf you already have a (personal or institutional) FigShare account, you can connect your GitHub. If you don’t have an account already, create one.\nThen go here and connect your GitHub account. Now when you go to create a new item, you can select ‘Import from connected integrations’ at the bottom of the upload wizard.\nNow when publishing a manuscript, you can cite the DOI for the code in the data availability statement, or in the reference section if the journal doesn’t use data availability statements."
  },
  {
    "objectID": "03_code.html",
    "href": "03_code.html",
    "title": "R Code",
    "section": "",
    "text": "We can improve our scripts by writing code which is:\n\nReadable\n\n\nUse a consistent style guide (like the tidyverse one)\nBe clear, concise, and consistent when naming objects, datasets, and functions\nBreak your scripts up into sections (Ctrl+Shift+R)\n\n\nReusable\n\n\nWrite functions to perform sets of operations\nUse iteration (for loops, or map())\nConsider creating packages for data and code used in multiple places\nBreak up long scripts into separate files (cleaning, manipulating, plotting)\n\n\nDocumented\n\n\nUse comments to explain why you did something the way you did\nInclude a README with each project to provide important context and background\n\nLet’s take a common example of some data analysis and apply the above principles when writing the code. First load the packages we need:\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(car)\n\nLet’s read in a dataset split into separate files. Instead of reading in each file separately, we can use readr::read_csv() to read them all in at once, bind them together into a single dataframe, and add a new column containing the filename of the data source. The dataset we’re working with contains measurements taken from mammals captured in the Chihuahuan desert. It is split into 4 separate .csv files based on time periods the measurements were recorded within.\n\n# Combine data from different collection periods\n\nfiles &lt;- list.files(path = \"data_raw\", \n                    pattern = \"\\\\.csv\", \n                    full.names = TRUE)\n\nsurveys &lt;- read_csv(files, id = \"source\")\n\nLet’s take a quick look at the mean hindfoot_length and weight for each species.\n\nsurveys |&gt; \n  group_by(species_id) |&gt; \n  summarise(across(c(hindfoot_length, weight), mean, na.rm = TRUE)) |&gt; \n  na.omit()\n\n# A tibble: 17 × 3\n   species_id hindfoot_length weight\n   &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt;\n 1 BA                    13     7   \n 2 DM                    36.0  42.5 \n 3 DO                    35.4  48.9 \n 4 DS                    50.0 120.  \n 5 NL                    32.4 158.  \n 6 OL                    20.6  32.6 \n 7 OT                    20.2  23.8 \n 8 OX                    19.1  21   \n 9 PE                    20.2  21.7 \n10 PF                    15.5   7.09\n11 PH                    26.1  30.7 \n12 PM                    20.4  21.6 \n13 PP                    21.7  16.3 \n14 RF                    17.4  13.4 \n15 RM                    16.4  10.3 \n16 SF                    29    54.8 \n17 SH                    28.9  75.0 \n\n\nTo understand how hindfoot_length varies based on the plot type the animal was captured in let’s use a boxplot.\n\nggplot(data = surveys, aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot() +\n  theme_bw() +\n  coord_flip() # Rotate the plot so the labels are easily readable\n\n\n\n\n\n\n\n\nLet’s say we wanted to create a separate scatterplot for each species showing hindfoot length vs weight. Even if we’re only interested in species codes with at least 100 valid observations, that’s still 11 plots.\n\nvalid_species &lt;-\n  surveys |&gt;\n  drop_na(all_of(c(\"weight\", \"hindfoot_length\"))) |&gt; \n  count(species_id) |&gt; \n  filter(n &gt;= 100) |&gt; \n  pull(species_id)\n\nLet’s first create a basic plot to show what we’re trying to produce.\n\n# Create an example of a plot\n\nggplot(surveys, aes(x = weight, y = hindfoot_length)) +\n  geom_point(alpha = 0.2) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nRather than write out the same code 15 times, this is a good time to write our own function. If we encapsulate all the plotting steps in a function, we can then use {purrr} to apply the function over the species and create the plots.\n\nplot_species &lt;- function(data, x_var, y_var, species) {\n  \n  # Useful to ensure any directories exist, or if not, create them\n  if (!dir.exists(\"figures\")) {\n    dir.create(\"figures\")\n  }\n  \n  # Capture the variable names as strings for the filenames\n  x_name &lt;- as_label(enquo(x_var))\n  y_name &lt;- as_label(enquo(y_var))\n  \n  # Create the plot\n  plots &lt;- \n    data |&gt; \n    filter(species_id == {{ species }}) |&gt;\n    ggplot(aes(x = {{ x_var }}, \n               y = {{ y_var }})) +\n    geom_point(alpha = 0.2) +\n    labs(title = paste(\"Species:\", species)) +\n    theme_minimal()\n  \n  # Construct the filename and save\n  file_path &lt;- paste0(\"figures/\", species, \"_\", x_name, \"_\", y_name, \".png\")\n  \n  ggsave(filename = file_path, plot = plots, width = 6, height = 4)\n}\n\n# purrr::walk iterates over a list or vector with a function\n\nwalk(valid_species, ~ plot_species(\n  data = surveys,\n  x_var = weight,            \n  y_var = hindfoot_length,   \n  species = .x \n))\n\nIn 1977, 24 experimental plots were established and each plot was manipulated in one of five ways. We can look at these plot types using dplyr::distinct()\n\nsurveys |&gt; distinct(plot_type)\n\n# A tibble: 5 × 1\n  plot_type                \n  &lt;chr&gt;                    \n1 Control                  \n2 Long-term Krat Exclosure \n3 Rodent Exclosure         \n4 Spectab exclosure        \n5 Short-term Krat Exclosure\n\n\nOne question we may have is how this impacts the mammals captured in these areas.\nLet’s look at plot_type to see how hindfoot_length differs.\n\nggplot(surveys, aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot() +\n  theme_minimal() +\n  coord_flip() \n\n\n\n\n\n\n\n\nThere may be a relationship between hindfoot_length and plot type.\nWe have a continuous dependent variable (hindfoot_length) and a categorical independent variable (plot_type), with multiple levels. An ANOVA would be an appropriate statistical test here, complemented by some post-hoc comparisons to test the individual differences in hindfoot_length across each plot_type.\nFirst we have to check assumptions:\n\nNormality\n\nAs with any general linear model we need to check that the data conforms to a normal distribution.\nWe can do this graphically or statistically. To do it graphically we plot the residuals in a histogram or QQ-plot, and to do it statistically we would use a Shapiro-Wilk test, but these tests can be quite conservativegiven large sample sizes.\nHere we’ll plot the residuals using a histogram and QQ-plot.\n\n# Run the ANOVA to get our residuals\nresiduals_anova &lt;- aov(hindfoot_length ~ plot_type, data = surveys)\n\n# Create plot space\npar(mfrow = c(1, 2))\n\n# Create histogram\nhist(residuals_anova$residuals)\n\n# Create QQ-plot\nqqPlot(residuals_anova$residuals, id = FALSE)\n\n\n\n\n\n\n\n\nThe residuals do not follow a normal distribution, but in this case, combined with our large sample size our ANOVA will be fairly robust to any violation of normality.\n\nHomogeneity - Equality of Variances\n\nWe also need to check whether the variance in hindfoot_length is roughly equal across all plot types. We can do this, again, using statistical methods, graphical methods, or both. Let’s use a boxplot.\n\nggplot(surveys, aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot(outliers = FALSE) +\n  theme_minimal() +\n  coord_flip() # Using coord flip to rotate the plot so the labels are easily readable\n\n\n\n\n\n\n\n\nThis assumption has been violated. Having removed the outliers, we can see that the whiskers of the Control and Long-term Krat Exclosure plots are much smaller than the other three plot types.\nWe have two options here. The first would be to use a non-parametric alternative, such as the Kruskall-Wallis H test. The second would be to use a parametric alternative that is robust to violations of this assumption. The most commonly used is the Welch test.\n\nIndependence of observations\n\nThis assumption states that the data has been collected from random samples and are not related. This is verified through good experimental design. We can state that we have satisfied this assumption.\nPerforming the ANOVA\n\noneway.test(hindfoot_length ~ plot_type, data = surveys, var.equal = FALSE)\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  hindfoot_length and plot_type\nF = 1082.8, num df = 4.0, denom df = 5099.1, p-value &lt; 2.2e-16\n\n\nAccording to this ANOVA there is a significant effect of plot type on hindfoot length. Now lets explore this effect further by conducting some post-hoc comparisons. We will use a simple bonferroni correction. This can be used to determine our new alpha level, by dividing our original alpha level (.05) by the number of comparisons we will be making (10)\n\npairwise.t.test(surveys$hindfoot_length, surveys$plot_type,\n                p.adjust.method = \"bonferroni\", pool.sd = FALSE)\n\n\n    Pairwise comparisons using t tests with non-pooled SD \n\ndata:  surveys$hindfoot_length and surveys$plot_type \n\n                          Control Long-term Krat Exclosure Rodent Exclosure\nLong-term Krat Exclosure  &lt; 2e-16 -                        -               \nRodent Exclosure          &lt; 2e-16 &lt; 2e-16                  -               \nShort-term Krat Exclosure 1.6e-09 &lt; 2e-16                  &lt; 2e-16         \nSpectab exclosure         &lt; 2e-16 &lt; 2e-16                  &lt; 2e-16         \n                          Short-term Krat Exclosure\nLong-term Krat Exclosure  -                        \nRodent Exclosure          -                        \nShort-term Krat Exclosure -                        \nSpectab exclosure         &lt; 2e-16                  \n\nP value adjustment method: bonferroni"
  },
  {
    "objectID": "03_code.html#writing-better-code",
    "href": "03_code.html#writing-better-code",
    "title": "R Code",
    "section": "",
    "text": "We can improve our scripts by writing code which is:\n\nReadable\n\n\nUse a consistent style guide (like the tidyverse one)\nBe clear, concise, and consistent when naming objects, datasets, and functions\nBreak your scripts up into sections (Ctrl+Shift+R)\n\n\nReusable\n\n\nWrite functions to perform sets of operations\nUse iteration (for loops, or map())\nConsider creating packages for data and code used in multiple places\nBreak up long scripts into separate files (cleaning, manipulating, plotting)\n\n\nDocumented\n\n\nUse comments to explain why you did something the way you did\nInclude a README with each project to provide important context and background\n\nLet’s take a common example of some data analysis and apply the above principles when writing the code. First load the packages we need:\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(car)\n\nLet’s read in a dataset split into separate files. Instead of reading in each file separately, we can use readr::read_csv() to read them all in at once, bind them together into a single dataframe, and add a new column containing the filename of the data source. The dataset we’re working with contains measurements taken from mammals captured in the Chihuahuan desert. It is split into 4 separate .csv files based on time periods the measurements were recorded within.\n\n# Combine data from different collection periods\n\nfiles &lt;- list.files(path = \"data_raw\", \n                    pattern = \"\\\\.csv\", \n                    full.names = TRUE)\n\nsurveys &lt;- read_csv(files, id = \"source\")\n\nLet’s take a quick look at the mean hindfoot_length and weight for each species.\n\nsurveys |&gt; \n  group_by(species_id) |&gt; \n  summarise(across(c(hindfoot_length, weight), mean, na.rm = TRUE)) |&gt; \n  na.omit()\n\n# A tibble: 17 × 3\n   species_id hindfoot_length weight\n   &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt;\n 1 BA                    13     7   \n 2 DM                    36.0  42.5 \n 3 DO                    35.4  48.9 \n 4 DS                    50.0 120.  \n 5 NL                    32.4 158.  \n 6 OL                    20.6  32.6 \n 7 OT                    20.2  23.8 \n 8 OX                    19.1  21   \n 9 PE                    20.2  21.7 \n10 PF                    15.5   7.09\n11 PH                    26.1  30.7 \n12 PM                    20.4  21.6 \n13 PP                    21.7  16.3 \n14 RF                    17.4  13.4 \n15 RM                    16.4  10.3 \n16 SF                    29    54.8 \n17 SH                    28.9  75.0 \n\n\nTo understand how hindfoot_length varies based on the plot type the animal was captured in let’s use a boxplot.\n\nggplot(data = surveys, aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot() +\n  theme_bw() +\n  coord_flip() # Rotate the plot so the labels are easily readable\n\n\n\n\n\n\n\n\nLet’s say we wanted to create a separate scatterplot for each species showing hindfoot length vs weight. Even if we’re only interested in species codes with at least 100 valid observations, that’s still 11 plots.\n\nvalid_species &lt;-\n  surveys |&gt;\n  drop_na(all_of(c(\"weight\", \"hindfoot_length\"))) |&gt; \n  count(species_id) |&gt; \n  filter(n &gt;= 100) |&gt; \n  pull(species_id)\n\nLet’s first create a basic plot to show what we’re trying to produce.\n\n# Create an example of a plot\n\nggplot(surveys, aes(x = weight, y = hindfoot_length)) +\n  geom_point(alpha = 0.2) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nRather than write out the same code 15 times, this is a good time to write our own function. If we encapsulate all the plotting steps in a function, we can then use {purrr} to apply the function over the species and create the plots.\n\nplot_species &lt;- function(data, x_var, y_var, species) {\n  \n  # Useful to ensure any directories exist, or if not, create them\n  if (!dir.exists(\"figures\")) {\n    dir.create(\"figures\")\n  }\n  \n  # Capture the variable names as strings for the filenames\n  x_name &lt;- as_label(enquo(x_var))\n  y_name &lt;- as_label(enquo(y_var))\n  \n  # Create the plot\n  plots &lt;- \n    data |&gt; \n    filter(species_id == {{ species }}) |&gt;\n    ggplot(aes(x = {{ x_var }}, \n               y = {{ y_var }})) +\n    geom_point(alpha = 0.2) +\n    labs(title = paste(\"Species:\", species)) +\n    theme_minimal()\n  \n  # Construct the filename and save\n  file_path &lt;- paste0(\"figures/\", species, \"_\", x_name, \"_\", y_name, \".png\")\n  \n  ggsave(filename = file_path, plot = plots, width = 6, height = 4)\n}\n\n# purrr::walk iterates over a list or vector with a function\n\nwalk(valid_species, ~ plot_species(\n  data = surveys,\n  x_var = weight,            \n  y_var = hindfoot_length,   \n  species = .x \n))\n\nIn 1977, 24 experimental plots were established and each plot was manipulated in one of five ways. We can look at these plot types using dplyr::distinct()\n\nsurveys |&gt; distinct(plot_type)\n\n# A tibble: 5 × 1\n  plot_type                \n  &lt;chr&gt;                    \n1 Control                  \n2 Long-term Krat Exclosure \n3 Rodent Exclosure         \n4 Spectab exclosure        \n5 Short-term Krat Exclosure\n\n\nOne question we may have is how this impacts the mammals captured in these areas.\nLet’s look at plot_type to see how hindfoot_length differs.\n\nggplot(surveys, aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot() +\n  theme_minimal() +\n  coord_flip() \n\n\n\n\n\n\n\n\nThere may be a relationship between hindfoot_length and plot type.\nWe have a continuous dependent variable (hindfoot_length) and a categorical independent variable (plot_type), with multiple levels. An ANOVA would be an appropriate statistical test here, complemented by some post-hoc comparisons to test the individual differences in hindfoot_length across each plot_type.\nFirst we have to check assumptions:\n\nNormality\n\nAs with any general linear model we need to check that the data conforms to a normal distribution.\nWe can do this graphically or statistically. To do it graphically we plot the residuals in a histogram or QQ-plot, and to do it statistically we would use a Shapiro-Wilk test, but these tests can be quite conservativegiven large sample sizes.\nHere we’ll plot the residuals using a histogram and QQ-plot.\n\n# Run the ANOVA to get our residuals\nresiduals_anova &lt;- aov(hindfoot_length ~ plot_type, data = surveys)\n\n# Create plot space\npar(mfrow = c(1, 2))\n\n# Create histogram\nhist(residuals_anova$residuals)\n\n# Create QQ-plot\nqqPlot(residuals_anova$residuals, id = FALSE)\n\n\n\n\n\n\n\n\nThe residuals do not follow a normal distribution, but in this case, combined with our large sample size our ANOVA will be fairly robust to any violation of normality.\n\nHomogeneity - Equality of Variances\n\nWe also need to check whether the variance in hindfoot_length is roughly equal across all plot types. We can do this, again, using statistical methods, graphical methods, or both. Let’s use a boxplot.\n\nggplot(surveys, aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot(outliers = FALSE) +\n  theme_minimal() +\n  coord_flip() # Using coord flip to rotate the plot so the labels are easily readable\n\n\n\n\n\n\n\n\nThis assumption has been violated. Having removed the outliers, we can see that the whiskers of the Control and Long-term Krat Exclosure plots are much smaller than the other three plot types.\nWe have two options here. The first would be to use a non-parametric alternative, such as the Kruskall-Wallis H test. The second would be to use a parametric alternative that is robust to violations of this assumption. The most commonly used is the Welch test.\n\nIndependence of observations\n\nThis assumption states that the data has been collected from random samples and are not related. This is verified through good experimental design. We can state that we have satisfied this assumption.\nPerforming the ANOVA\n\noneway.test(hindfoot_length ~ plot_type, data = surveys, var.equal = FALSE)\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  hindfoot_length and plot_type\nF = 1082.8, num df = 4.0, denom df = 5099.1, p-value &lt; 2.2e-16\n\n\nAccording to this ANOVA there is a significant effect of plot type on hindfoot length. Now lets explore this effect further by conducting some post-hoc comparisons. We will use a simple bonferroni correction. This can be used to determine our new alpha level, by dividing our original alpha level (.05) by the number of comparisons we will be making (10)\n\npairwise.t.test(surveys$hindfoot_length, surveys$plot_type,\n                p.adjust.method = \"bonferroni\", pool.sd = FALSE)\n\n\n    Pairwise comparisons using t tests with non-pooled SD \n\ndata:  surveys$hindfoot_length and surveys$plot_type \n\n                          Control Long-term Krat Exclosure Rodent Exclosure\nLong-term Krat Exclosure  &lt; 2e-16 -                        -               \nRodent Exclosure          &lt; 2e-16 &lt; 2e-16                  -               \nShort-term Krat Exclosure 1.6e-09 &lt; 2e-16                  &lt; 2e-16         \nSpectab exclosure         &lt; 2e-16 &lt; 2e-16                  &lt; 2e-16         \n                          Short-term Krat Exclosure\nLong-term Krat Exclosure  -                        \nRodent Exclosure          -                        \nShort-term Krat Exclosure -                        \nSpectab exclosure         &lt; 2e-16                  \n\nP value adjustment method: bonferroni"
  },
  {
    "objectID": "01_projects.html",
    "href": "01_projects.html",
    "title": "RStudio Projects",
    "section": "",
    "text": "To allow Git to work properly with RStudio, and to ensure your local Git install is linked with your GitHub account, we need to open Git bash (windows) or Terminal (macOS) and enter:\ngit config --global user.name \"Jane Doe\"\ngit config --global user.email \"jane@example.com\"\nsubstituting your name and the email associated with your GitHub account. The user.name you give does not have to be the same as your GitHub username. It can be your actual first and last name."
  },
  {
    "objectID": "01_projects.html#final-set-up",
    "href": "01_projects.html#final-set-up",
    "title": "RStudio Projects",
    "section": "",
    "text": "To allow Git to work properly with RStudio, and to ensure your local Git install is linked with your GitHub account, we need to open Git bash (windows) or Terminal (macOS) and enter:\ngit config --global user.name \"Jane Doe\"\ngit config --global user.email \"jane@example.com\"\nsubstituting your name and the email associated with your GitHub account. The user.name you give does not have to be the same as your GitHub username. It can be your actual first and last name."
  },
  {
    "objectID": "01_projects.html#generate-a-personal-access-token",
    "href": "01_projects.html#generate-a-personal-access-token",
    "title": "RStudio Projects",
    "section": "Generate a personal access token",
    "text": "Generate a personal access token\nLog into your GitHub account. Select your profile picture in the top right corner and select ‘settings’. Scroll to the bottom of the menu bar on the left and select ‘&lt;&gt; Developer settings’-&gt; ‘Personal access tokens’ -&gt; ‘Tokens (classic)’.\nFrom here, select ‘Generate new token’ -&gt; ‘Generate new token (classic)’.\nUnder ‘Note’ give your token a name so that you can remember what it is used for. For example tom-work-laptop. You can then set an expiration date.\nIf you would like to use the same token forever, so that you don’t have to return to GitHub to generate a new token, give it a somewhat generic name and set the expiration date to No Expiration.\nFor the ‘scopes’, we recommend selecting ‘repo’, ‘workflow’ and ‘user’. There are several reasons why you would want to create different personal access tokens, but scopes are one important reason. These define what type of access you need. ‘Fine-grained tokens’ take this even further by allowing you to specify different access types for different repositories."
  },
  {
    "objectID": "01_projects.html#create-github-repository-rstudio-project",
    "href": "01_projects.html#create-github-repository-rstudio-project",
    "title": "RStudio Projects",
    "section": "Create GitHub repository & RStudio project",
    "text": "Create GitHub repository & RStudio project\nWe’re going to work in an RStudio project connected to a GitHub repository.\nFirst we create the repository in GitHub:\n\nGo to github.com, sign in, then click the green ‘New’ button.\nName it “r-data-science”, leave the rest as default, then click ‘create repository’.\nCopy the github.com address in the ‘Quick set up box’.\nOpen RStudio and select File -&gt; New project -&gt; Version control -&gt; Git -&gt; and paste the address into the ‘Repository URL’ box.\n\nIn the box called ‘Create project as subdirectory of:’ you need to select a location on your machine. It’s a good idea to create a folder called something like ‘projects’ in your user folder and select this every time, to group your repositories together in the same place on your machine(s). Let’s do that by clicking ‘Browse’, navigating to your user folder, and creating a new folder called ‘projects’ before selecting it and clicking ‘create project’.\nRStudio opens a new project called r-data-science. RStudio projects are essentially the .RProj file - this file tells RStudio that this folder is home to the project, and to use the folder as the ‘working directory’, or the place where R is looking when you ask it to load data or save an output."
  },
  {
    "objectID": "01_projects.html#set-up-folders",
    "href": "01_projects.html#set-up-folders",
    "title": "RStudio Projects",
    "section": "Set up folders",
    "text": "Set up folders\nCreate the following folders from within RStudio:\n\ndata_raw: holds the raw, untouched data.\ndata: holds cleaned data.\nfigures: holds figures and plots.\nsrc: holds analysis script(s).\n\nThere are many ways of setting up project folders, but the idea is to pick a convention and stick to it across different projects to stay organised and save time.\nDownload this zipped dataset, move it into data_raw, and unzip it.\nCreate a new R script (Ctrl+Shift+N), call it analysis.R and save it in the src folder."
  },
  {
    "objectID": "02_version-control.html",
    "href": "02_version-control.html",
    "title": "Version Control",
    "section": "",
    "text": "When working on your own projects, or collaborating with others, you’re likely to run into several problems:\nUsing a proper version control system solves these problems and makes collaborating on plain text documents like code much cleaner and simpler. We’ll be using Git (installed locally on our machines) alongside GitHub (a cloud service) to demo a simple collaborative workflow."
  },
  {
    "objectID": "02_version-control.html#committing-with-git",
    "href": "02_version-control.html#committing-with-git",
    "title": "Version Control",
    "section": "Committing with Git",
    "text": "Committing with Git\nNow that we’ve set up our project folder, it’s a good time to make our first ‘commit’ to Git.\nSelect the Git tab in RStudio and tick the ‘staged’ box for all the files (or select one file, press Ctrl+A, and then tick one of the selected files to tick all). Click Commit and type a commit message detailing the changes (let’s go with “set up project” for now) and select the ‘Commit’ button.\nYou may now be presented with a pop-up asking you to connect to Github. Here you will need to paste in your github token.\nYou can now ‘push’ your commit up to GitHub, so that the GitHub repository reflects the current state of the repository on your machine."
  },
  {
    "objectID": "02_version-control.html#working-with-branches",
    "href": "02_version-control.html#working-with-branches",
    "title": "Version Control",
    "section": "Working with branches",
    "text": "Working with branches\nGit uses branches to make it easier to separate out new work and have more control over merging new work into the existing project. Let’s create a new branch in the Git pane by clicking the button with the purple shapes next to ‘main’. Let’s call it load-packages, and leave everything as default. Usually you would do a bit more work in a new branch before merging it into the main branch, but for our purposes we’ll just add some library() calls up the top of our script to load the packages we’ll need.\nOpen analysis.R and enter the following up the top:\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(purrr)\n\nSave the file and open the Git pane in RStudio. You should see the script file listed there.Lets stage, commit, and enter a commit message such as “add package loading”, commit, and push.\nWe’ve made this commit on the load-packages branch locally, and have now also pushed it up to the load-packages branch in our GitHub repository. Now we need to initiate what is called a ‘pull request’ in GitHub."
  },
  {
    "objectID": "02_version-control.html#merging-with-pull-requests",
    "href": "02_version-control.html#merging-with-pull-requests",
    "title": "Version Control",
    "section": "Merging with pull requests",
    "text": "Merging with pull requests\nA pull request is a proposal to merge a set of changes from one branch into another. In a pull request, collaborators can review and discuss the proposed set of changes before they integrate the changes into the main codebase. Pull requests display the differences, or diffs, between the content in the source branch and the content in the target branch.\nHead to github.com, sign in if you aren’t already, click your profile icon top right and select ‘repositories’. Your ‘r-data-science’ repo should be up the top as it has just had changes pushed to it. Select the repository and click the big green ‘Compare & pull request’ button up the top. You should then see a page with an overview of the two branches and a green ‘Create pull request’ button. After clicking that, you’ll see a review page that shows a high-level overview of the changes between your branch (the compare branch) and the repository’s base branch. You can add a summary of the proposed changes, review the changes made by commits, add labels, milestones, and assignees, and @mention individual contributors or teams. After you’re happy with the proposed changes, you can merge the pull request.\nIn this example, you should be able to go ahead and merge the pull request straight away. But when working with other people, it’s fairly common to run into merge conflicts. Merge conflicts occur when people make different changes to the same line of the same file, or when one person edits a file and another person deletes the same file. You must resolve all merge conflicts before you can merge a pull request on GitHub. If you have a merge conflict between the compare branch and base branch in your pull request, you can view a list of the files with conflicting changes above the Merge pull request button. The Merge pull request button is deactivated until you’ve resolved all conflicts between the compare branch and base branch."
  },
  {
    "objectID": "02_version-control.html#collaborating-with-git",
    "href": "02_version-control.html#collaborating-with-git",
    "title": "Version Control",
    "section": "Collaborating with Git",
    "text": "Collaborating with Git\nYou can invite collaborators to give them access to your repo. This allows other people to pull from and push to the repo, and perform a variety of other tasks.\nVersion control with Git and GitHub is a complex topic and not tsomething we can spend too much time on here, so please see this online introductory Git lesson if you’d like to learn more."
  },
  {
    "objectID": "04_dependencies.html",
    "href": "04_dependencies.html",
    "title": "Managing Dependencies",
    "section": "",
    "text": "One of the benefits of using R to analyse data is gaining access to the incredible ecosystem of packages that have been developed to make it easier to perform all kinds of different analyses. Packages are often updated to fix bugs, add new functionality, or change existing functionality. Sometimes this means code breaks. Something that used to work with a previous version of a package no longer works, so the code stops running. This can be frustrating and time consuming to fix. Fortunately, by smartly managing dependencies (the packages that our code depends on to work), we can largely avoid the problem."
  },
  {
    "objectID": "04_dependencies.html#introducing-renv",
    "href": "04_dependencies.html#introducing-renv",
    "title": "Managing Dependencies",
    "section": "Introducing renv",
    "text": "Introducing renv\nrenv (short for r environment) makes your R projects:\n\nIsolated: Installing a new or updated package for one project won’t break your other projects, and vice versa. That’s because renv gives each project its own private package library.\nPortable: Easily transport your projects from one computer to another, even across different platforms. renv makes it easy to install the packages your project depends on.\nReproducible: renv records the exact package versions you depend on, and ensures those exact versions are the ones that get installed wherever the project goes.\n\nrenv can be installed onto your machine like any other package at any time during the lifecycle of your project. In the console:\n\ninstall.packages(\"renv\")\n\nTo use renv in your project, in the console:\n\nrenv::init()\n\nThis will set up a project library in a folder called renv, containing all the packages you’re currently using. The packages (and all the metadata needed to reinstall them) are recorded into a lockfile, renv.lock, and a .Rprofile file ensures that the library is used every time you open that project.\nAs you work on your project, you will install and upgrade packages, either using install.packages() and update.packages() or renv::install() and renv::update(). After you’ve confirmed your code works as expected, use renv::snapshot() to record the packages and their sources in an updated lockfile.\nLater, if you need to share your code with someone else or run your code on new machine, your collaborator (or you) can call renv::restore() to install the specific package versions recorded in the lockfile.\nWhen we use renv commands we use the :: notation so we don’t actually have to load the renv package, and we always enter renv commands in the console. We don’t preserve them in our script.\nThe below graphic shows a diagram of the standard workflow:"
  },
  {
    "objectID": "04_dependencies.html#testing-it-out",
    "href": "04_dependencies.html#testing-it-out",
    "title": "Managing Dependencies",
    "section": "Testing it out",
    "text": "Testing it out\nRun renv::init() and you should see some activity in the console and you’ll see some new files in the Git pane.\nWe now have a renv.lock file that has recorded the packages, and their versions, that are loaded in our script (or loaded in any scripts within our project).\nLets install and load another package, as if we were going to use it in our script. In the console:\n\ninstall.packages(\"ratdat\")\n\nrenv should tell you in the console that it is going to download the package from CRAN and install it within the project/renv folder. You’ll need to hit Shift+Y to confirm. It downloads the package, stores it within a central package cache, and links it into your project package library. This means if you want to link that same package in a different project renv will link it from the central cache without having to download it again. Now let’s load the ratdat package in our script as if we were going to use it.\n\nlibrary(\"ratdat\")\n\nLet’s pretend we used the package and were happy with our code. We can check the status of our project to see if renv has detected the new package.\n\nrenv::status()\n\nrenv should tell you that ratdat is installed and used, but not recorded in the lock file. To fix this we take a snapshot to update the lock file.\n\nrenv::snapshot()\n\nYou should be prompted to allow the lock file to be updated with the package (Shift+Y to confirm).\nAs we’re not actually using this package, we can remove it from our project by running:\n\nrenv::remove(\"ratdat\")\n\nAnd deleting the library(\"ratdat\") call above. Now we can update our lock file again:\n\nrenv::snapshot()\n\nIf someone clones the project from GitHub, and they have renv installed, they can renv::restore() the packages within the lockfile so that these package versions will be installed into the project package library on their machine too. This means they have the same packages, and the same versions, installed in their project library as the person who created the code."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducible & Collaborative Data Science with R",
    "section": "",
    "text": "Dr Tom Saunders & Dr Toby Johnson\nCentre for eResearch\nUniversity of Auckland\nWelcome to the workshop repository for Reproducible & Collaborative Data Science with R.\n\nGetting Set Up\nFollow the instructions on the set up page to install some software and create a GitHub account before the workshop.\n\n\nObjectives\nThe primary objective of this workshop is to equip emerging researchers with practical skills to unlock the potential of their R scripts by making their code reproducible, shareable, and citable.\nMost R users do not have a background in computer science or software development, but instead come with expertise from particular research domains. This presents an opportunity to empower researchers to apply software development principles to the code they write to ensure their work has maximum impact. We will cover the following concepts in this workshop:\n\nOrganising work in projects\nWriting readable and modular R code\nCollaborating with version control\nManaging package dependencies\nPublishing software projects\n\nEach of these topics alone could easily fill a 1.5 hour workshop, so our treatment of them will necessarily be brief. But our main aim here is to introduce these concepts, show how they are used together, and walk through how to start applying them to your research projects."
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Set Up",
    "section": "",
    "text": "1. Install or update R\nIf using a device managed by your organisation, install R from your organisational software repository or contact your IT department for help.\nTo download and install R on a personal machine:\n\nWindows: Select ‘base’, then ‘Download R for Windows’. Run the installer\nMac:\nLinux\n\n\n\n2. Install or update RStudio\nIf using a device managed by your organisation, install RStudio from your organisational software repository or contact your IT department for help.\nTo download and install RStudio on a personal machine (requires administrator privileges):\n\nGo here and click ‘Download RStudio Desktop’ underneath ‘2: Install RStudio’, or scroll down and select the appropriate version for your operating system.\n\n\n\n3. Install R packages\nOpen RStudio and install the following R packages by:\n\nSelecting Tools &gt; Install Packages &gt; and entering readr, dplyr, tidyr, ggplot2, purrr, renv and select ‘Install’.\n\nOR\n\nRunning the following command in the console:\n\n\ninstall.packages(c(\"readr\", \"dplyr\", \"tidyr\", \"ggplot2\", \"purrr\", \"renv\"))\n\n\n\n4. Install Git\nInstall Git on Windows:\n\nDownload and install Git for Windows.\nDuring installation, when asked about “Adjusting your PATH environment”, make sure to select “Git from the command line and also from 3rd-party software”. Otherwise, accept the default options.\n\nInstall Git on Mac:\n\nOpen the Terminal app, type git --version and press Enter/Return.\nIf it’s not installed already, follow the instructions to Install the “command line developer tools”.\nDo not click “Get Xcode” - it will take too long and is not necessary for our Git lesson.\n\nInstall Git on Linux:\n\nIf Git is not already available, install it via your package manager.\nFor Debian/Ubuntu run sudo apt-get install git and for Fedora run sudo dnf install git.\n\n\n\n5. Create a GitHub account\nGo to github.com and create a free account. If you use your organisational email address you may be eligible for a free upgrade to GitHub Education. If you would like to remain anonymous, choose an appropriate username and see these instructions for keeping your email address private."
  },
  {
    "objectID": "slides.html#hi",
    "href": "slides.html#hi",
    "title": "Reproducible & Collaborative Data Science In R",
    "section": "Hi!",
    "text": "Hi!\n\nToday we’re getting hands-on to make R code better.\nDon’t worry if you aren’t able to follow every step.\nPut a pink post-it on your screen to indicate you’re stuck.\nRaise hand for a question at any time."
  }
]